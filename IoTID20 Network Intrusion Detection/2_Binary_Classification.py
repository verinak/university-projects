# -*- coding: utf-8 -*-
"""2_Binary_Classification.ipynb

Automatically generated by Colab.

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns
import warnings, time

from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, cross_validate, KFold
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, average_precision_score
from sklearn.calibration import CalibratedClassifierCV

warnings.filterwarnings("ignore")  # Ignore all warnings
pd.set_option('display.max_columns', None)  # Display all columns

"""# Loading Data

### Load data after cleaning
"""

from google.colab import drive
drive.mount('/content/drive')
dir_path = '/content/drive/MyDrive/computation data/'

data_path = dir_path + 'data_cleaned.csv'
# data_path = r'data/data_cleaned.csv'

df = pd.read_csv(data_path)

data_path = dir_path + 'x_cleaned.csv'
# data_path = r'data/x_cleaned.csv'

dataframe = pd.read_csv(data_path)
preprocessed_data = dataframe.to_numpy()

"""### Apply PCA and LDA to cleaned data"""

print("Applying PCA to preprocessed data ... ", end="")
pca = PCA()
pca.fit(preprocessed_data)
pca_features = pca.transform(preprocessed_data)

num_pca_features = pca_features.shape[1]
print("Number of PCA Features:", num_pca_features)
print("Done")

print("Applying LDA to preprocessed data based on Label column... ", end="")
lda_label = LinearDiscriminantAnalysis()
lda_label.fit(preprocessed_data, df['Label'])
lda_features_label = lda_label.transform(preprocessed_data)
print("Done")
print(lda_features_label)

print("Applying LDA to preprocessed data based on Category column... ", end="")
lda_category = LinearDiscriminantAnalysis()
lda_category.fit(preprocessed_data, df['Cat'])
lda_features_category = lda_category.transform(preprocessed_data)
print("Done")
print(lda_features_category)

print("Applying LDA to preprocessed data based on Subcategory column... ", end="")
lda_subcategory = LinearDiscriminantAnalysis()
lda_subcategory.fit(preprocessed_data, df['Sub_Cat'])
lda_features_subcategory = lda_subcategory.transform(preprocessed_data)
print("Done")
print(lda_features_subcategory)

"""We will define a function that performs PCA with a given number of components followed by LDA to avoid redundancy in our code"""

def perform_pca_lda(y, X=pca_features, n_components=72):
  pca_data = X[:, :n_components]

  lda = LinearDiscriminantAnalysis()
  lda.fit(pca_data, y)
  pca_lda_data = lda.transform(pca_data)

  return pca_lda_data

def print_pca_lda_results(pca_lda_data):
  # Print the shape of the transformed data
  print("Shape of transformed data:", pca_lda_data.shape)

  # Print the first few rows of the transformed data
  print("Transformed data:")
  print(pca_lda_data)

"""# Model Development

## Functions

We will first define functions to train and fine tune the SVM model to avoid redundancy in our code

### Train Model
"""

def train_LinearSVC_Model(X, y, penalty='l2', loss='hinge', C=1.0, max_iter=100):

    """
    Implements training and testing of LinearSVC model with an 80/20 train-test split.

    Parameters:
        X: DataFrame of X features.
        y: Series of y variable.
        parameters that can be passed to LinearSVC function are added as optional parameters.
        check LinearSVC official documentation for more details.

    Returns:
        classifier: trained LinearSVC classifier.
        metrics: dictionary of evaluation metrics.
        conf_mat: ndarray of confusion matrix.
    """

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    classifier = LinearSVC(penalty=penalty, loss=loss, max_iter=max_iter, C=C)

    # Train the classifier
    start_time = time.time()
    classifier.fit(X_train, y_train)
    fit_time = time.time() - start_time

    # Predict on the test set
    start_time = time.time()
    y_pred = classifier.predict(X_test)
    predict_time = time.time() - start_time

    # Calculate evaluation metrics

    # Confusion matrix
    conf_mat = confusion_matrix(y_test, y_pred)

    # Calibrate the classifier for probability estimation
    calibrated_classifier = CalibratedClassifierCV(classifier, method='sigmoid', cv='prefit')
    calibrated_classifier.fit(X_train, y_train)
    y_scores = calibrated_classifier.predict_proba(X_test)

    # Compute precision-recall pairs for each class
    precision = dict()
    recall = dict()
    average_precision = dict()
    for i in range(len(set(y))):
        precision[i], recall[i], _ = precision_recall_curve(y_test == i, y_scores[:, i])
        average_precision[i] = average_precision_score(y_test == i, y_scores[:, i])
    precision_recall = [precision, recall, average_precision]


    # Calculate ROC curve
    fpr, tpr, thresholds = roc_curve(y_test, y_pred)
    # Calculate ROC AUC score
    roc_auc = roc_auc_score(y_test, y_pred)
    metrics = {
        'n_classes':len(set(y)),
        'accuracy': round(accuracy_score(y_test, y_pred) * 100, 2),
        'balanced_accuracy': round(balanced_accuracy_score(y_test, y_pred) * 100, 2),
        'fit_time': round(fit_time  * 1000),
        'predict_time': round(predict_time  * 1000),
        'misclassified': np.sum(conf_mat) - np.sum(np.diag(conf_mat)),
        'precision': round(precision_score(y_test, y_pred), 3),
        'recall': round(recall_score(y_test, y_pred), 3),
        'f1_score': round(f1_score(y_test, y_pred, average='weighted'), 3),
        'fpr': fpr,
        'tpr': tpr,
        'roc_auc': roc_auc,
    }


    return classifier, metrics, conf_mat, precision_recall

"""### Print Metrics"""

def print_metrics(metrics, conf_mat, precision_recall):
    """
    Prints evaluation metrics and confusion matrix of model trained with train_LinearSVC_Model() function.

    Parameters:
        metrics: dictionary of evaluation metrics returned by train_LinearSVC_Model() function.
        conf_mat: ndarray of confusion matrix returned by train_LinearSVC_Model() function.
        precision_recall: list of precision-recall curve data.
    """

    # Print evaluation metrics
    print(f"Accuracy: {metrics['accuracy']}%")
    print(f"Balanced accuracy: {metrics['balanced_accuracy']}%")
    print(f"Precision: {metrics['precision']}")
    print(f"Recall: {metrics['recall']}")
    print(f"Weighted F1 score: {metrics['f1_score']}")
    print(f"Fit time: {metrics['fit_time']} ms")
    print(f"Predict time: {metrics['predict_time']} ms")

    print()
    print(f"Number of misclassified: {metrics['misclassified']}")

    # Plot confusion matrix, roc-auc curve, and pr curve
    sns.set(style="darkgrid")

    fig = plt.figure(figsize=(11,5), layout='constrained')
    gs = fig.add_gridspec(2,2)

    ax0 = fig.add_subplot(gs[0:2,0])
    sns.heatmap(conf_mat, annot=True, fmt='d', ax=ax0)
    ax0.set_title('Confusion Matrix')
    ax0.set_xlabel('Predicted')
    ax0.set_ylabel('True')

    ax1 = fig.add_subplot(gs[0,1])
    ax1.plot(metrics['fpr'], metrics['tpr'], label = 'ROC curve (area = %0.2f)' % metrics['roc_auc'], color = 'darkorange', lw = 2)
    ax1.plot([0, 1], [0, 1],  lw=1.5, linestyle='--', color = 'darkslateblue')
    ax1.set_xlim([0.0, 1.0])
    ax1.set_ylim([0.0, 1.0])
    ax1.legend()
    ax1.set_xlabel('False Positive Rate (FPR)')
    ax1.set_ylabel('True Positive Rate (TPR)')
    ax1.set_title('ROC Curve')

    precision = precision_recall[0]
    recall = precision_recall[1]
    average_precision = precision_recall[2]

    colors = sns.color_palette('Set2')
    #colors = ['#f6f4d2', '#cbdfbd', '#f19c79', '#a44a3f']


    ax2 = fig.add_subplot(gs[1,1])

    for i, color in zip(range(metrics['n_classes']), colors):
        ax2.plot(recall[i], precision[i], color=color, lw=2.5, label='Precision-recall curve of class {0} (area = {1:0.2f})'.format(i, average_precision[i]))

    ax2.set_xlim([0.0, 1.0])
    ax2.set_ylim([0.0, 1.1])
    ax2.legend()
    ax2.set_xlabel('Recall')
    ax2.set_ylabel('Precision')
    ax2.set_title('Precision_recall Curve')

    plt.show()

"""### Fine-tune the Model"""

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.svm import LinearSVC


def fine_tune_LinearSVC(X, y, test_size=0.2, random_state=None, cv=5, scoring='accuracy', n_iter=200):
    """
    Performs hyperparameter tuning for LinearSVC model using RandomizedSearchCV with data splitting.
    Parameters:
        X: DataFrame of X features.
        y: Series of y variable.
        test_size: Proportion of data for the test set (default: 0.2).
        random_state: Seed for random splitting (default: None).
        cv: Number of folds for cross-validation (default: 5).
        scoring: Evaluation metric to use for scoring (default: 'accuracy').
        n_iter: Number of iterations for randomized search (default: 100).

    Returns:
        best_params: Dictionary containing the best hyperparameters found (C, loss, tol).
    """

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # Define hyperparameter distributions
    param_dist = {
      'C': [0.001, 0.01, 0.1, 1, 10, 100],
      'loss': ["hinge", "squared_hinge"],
      #'tol': [1e-3, 1e-4, 1e-5]
    }

    clf = LinearSVC()
    search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=cv, scoring=scoring, n_iter=n_iter, random_state=random_state)

    search.fit(X_train, y_train)

    # Access best parameters
    best_params = search.best_params_

    return best_params

"""## Binary Classification

### Without dimentionality reduction
"""

print("Training model without dimentionality reduction..")
classifier, metrics, conf_mat, precision_recall = train_LinearSVC_Model(preprocessed_data, df['Label'])

print_metrics(metrics, conf_mat, precision_recall)

"""##### **Fine tuning**"""

# fine_tune_LinearSVC(preprocessed_data, df['Label'])

print("Training model without dimentionality reduction..")
Tuned_classifier, Tuned_metrics, Tuned_conf_mat, Tuned_conf_precision_recall = train_LinearSVC_Model(preprocessed_data, df['Label'], C=10.0, loss="squared_hinge")

print_metrics(Tuned_metrics, Tuned_conf_mat, Tuned_conf_precision_recall)

"""We can see that the model gives good accuracy. However, the fit and predit time are too large for an iot IDS model, so we need to use dimentionality reduction and fine tune the models to get lower fit and predict times.

### LDA Only

#### Using Label Column for LDA
"""

print("Training model with Label LDA feature..")
classifier, metrics, conf_mat, precision_recall = train_LinearSVC_Model(lda_features_label, df['Label'])
metrics_lda_label=metrics

print_metrics(metrics, conf_mat,precision_recall)

"""#### Using Category Column for LDA"""

print("Training model with Category LDA features..")
classifier, metrics, conf_mat, precision_recall = train_LinearSVC_Model(lda_features_category, df['Label'])
lda_categories=metrics

print_metrics(metrics, conf_mat, precision_recall)

"""##### **Fine tuning**"""

# fine_tune_LinearSVC(lda_features_category, df['Label'])

print("Training Tuned model with Category LDA features..")
Tuned_cat_classifier, Tuned_cat_metrics, Tuned_cat_conf_mat, Tuned_cat_precision_recall = train_LinearSVC_Model(lda_features_category, df['Label'], loss="hinge", C=1.0)
metrics_lda_categories=Tuned_cat_metrics

print_metrics(Tuned_cat_metrics, Tuned_cat_conf_mat, Tuned_conf_precision_recall)

"""#### Using Subcategory Column for LDA"""

print("Training model with Subcategory LDA features..")
classifier, metrics, conf_mat, precision_recall = train_LinearSVC_Model(lda_features_subcategory, df['Label'])
lda_subcategories=metrics

print_metrics(metrics, conf_mat,precision_recall)

"""##### Fine tuning"""

# fine_tune_LinearSVC(lda_features_subcategory, df['Label'])

print("Training Tuned model with Subcategory LDA features..")
Tuned_subcat_classifier, Tuned_subcat_metrics, Tuned_subcat_conf_mat, Tuned_subcat_precision_recall = train_LinearSVC_Model(lda_features_subcategory, df['Label'], C=100.0, loss="hinge")
metrics_lda_subcategories=Tuned_subcat_metrics

print_metrics(Tuned_subcat_metrics, Tuned_subcat_conf_mat, Tuned_subcat_precision_recall)

"""The models' accuracy are already high before fine tuning. However, fine tuning helped reduce fit time, as shown below."""

# heya el times m4 sabta m3 kol run bs lw 3amalna run kaza mara fi range arkam keda howa eli byetla3 fl 8aleb

accuracy_data1 = {
    'Model': ['With fine tuning', 'without fine tuning'],
    'Fit time': [metrics_lda_categories['fit_time'],lda_categories['fit_time']]
}

accuracy_data2 = {
    'Model': ['With fine tuning', 'without fine tuning'],
    'Fit time': [metrics_lda_subcategories['fit_time'],lda_subcategories['fit_time']]
}

df_accuracy = pd.DataFrame(accuracy_data1)

sns.set(style="darkgrid")
pal = {'With fine tuning': "maroon", 'without fine tuning': "darkblue"}

# Create the bar plot
plt.figure(figsize=(11, 4))
plt.subplot(1,2,1)
ax = sns.barplot(x="Model",
                 y="Fit time",
                 data=df_accuracy,
                 palette=pal,
                 linewidth=2,
                 capsize=.1)

plt.ylabel("Fit Time", fontsize=14)
plt.xlabel("Category LDA", fontsize=14)

df_accuracy = pd.DataFrame(accuracy_data2)

plt.subplot(1,2,2)
ax = sns.barplot(x="Model",
                 y="Fit time",
                 data=df_accuracy,
                 palette=pal,
                 linewidth=2,
                 capsize=.1)

plt.ylabel("Fit Time", fontsize=14)
plt.xlabel("Subcategory LDA", fontsize=14)

plt.subplots_adjust(wspace=0.5)  # Adjust the width space between subplots

plt.suptitle("Fit time Comparison before and after fine tuning", fontsize=16)
plt.show()

"""### Combining PCA and LDA

We can see that performing LDA on Sub_Cat column gives the best results, but we will combine PCA and LDA to see if we can optimize the fit and predict times, or the accuracy of models with other LDA columns

#### First 11 components (best from skree plot)

#### Using Subcategory LDA and 11 PCA components
"""

pca_lda_data = perform_pca_lda(y=df['Sub_Cat'], n_components=11)
print_pca_lda_results(pca_lda_data)

print("Training model with Subcategory PCA features..")
classifier, metrics, conf_mat, precision_recall = train_LinearSVC_Model(pca_lda_data, df['Label'])

print_metrics(metrics, conf_mat, precision_recall)

"""##### Fine tuning"""

# fine_tune_LinearSVC(pca_lda_data, df['Label'])

print("Training Tuned model with Subcategory PCA features..")
Tuned_pca11_classifier, Tuned_pca11_metrics, Tuned_pca11_conf_mat, Tuned_pca11_precision_recall = train_LinearSVC_Model(pca_lda_data, df['Label'], loss="squared_hinge", C=1.0)
metrics_pca11_subcategories=Tuned_pca11_metrics

print_metrics(Tuned_pca11_metrics, Tuned_pca11_conf_mat,Tuned_pca11_precision_recall)

"""#### Using Category LDA and 11 PCA components"""

pca_lda_data = perform_pca_lda(y=df['Cat'], n_components=11)
print_pca_lda_results(pca_lda_data)

print("Training model with category PCA features..")
classifier, metrics, conf_mat, precision_recall = train_LinearSVC_Model(pca_lda_data, df['Label'])

print_metrics(metrics, conf_mat, precision_recall)

"""##### Fine tuning"""

# fine_tune_LinearSVC(pca_lda_data, df['Label'])

print("Training Tuned model with category PCA features..")
Tuned_pca11_classifier, Tuned_pca11_metrics, Tuned_pca11_conf_mat, Tuned_pca11_precision_recall = train_LinearSVC_Model(pca_lda_data, df['Label'], loss="squared_hinge", C=1.0)
metrics_pca11_categories=Tuned_pca11_metrics

print_metrics(Tuned_pca11_metrics, Tuned_pca11_conf_mat, Tuned_pca11_precision_recall)

"""## Using Subcategory LDA and 30 PCA components"""

pca_lda_data = perform_pca_lda(y=df['Sub_Cat'], n_components=30)
print_pca_lda_results(pca_lda_data)

print("Training model with 30 Subcategory PCA features..")
classifier, metrics, conf_mat, precision_recall = train_LinearSVC_Model(pca_lda_data, df['Label'])
metrics_pca30_subcategories=metrics

print_metrics(metrics, conf_mat, precision_recall)

metrics_data = {
    "Model": ["With Label LDA Feature", "With Category LDA Features", "With Subcategory LDA Features",
              "11 PCA components and LDA using Subcategory column", "11 PCA components and LDA using Category column",
              '30 PCA components and LDA using Subcategory column'],
}

# metrics to include
metrics_to_include = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1_score', 'fit_time', 'predict_time']

# add metrics to metrics_data dictionary
for metric in metrics_to_include:
    metrics_data[metric.capitalize()] = [globals().get(f"metrics_{name}")[metric] for name in ['lda_label', 'lda_categories', 'lda_subcategories', 'pca11_subcategories', 'pca11_categories','pca30_subcategories']]

# Create dataframe
df_metrics = pd.DataFrame(metrics_data)

# draw comparaison table
df_metrics.sort_values(by="Balanced_accuracy", ascending=False, inplace=True)
comparison_table = df_metrics.style.background_gradient(cmap='YlGn').set_properties(**{
    'font-family': 'Lucida Calligraphy',
    'color': 'neon',
    'font-size': '15px'
})
comparison_table

# Drop two models with smallest balanced accuracy
df_metrics.sort_values(by="Balanced_accuracy", ascending=False, inplace=True)

# Get index of rows
dropped_rows_indices = df_metrics.tail(2).index.tolist()

dropped_rows = df_metrics.loc[dropped_rows_indices]

print("Dropped rows:")
print(dropped_rows.to_string())

# Remove rows
new_df = df_metrics.iloc[:-2]

comparison_table = new_df[['Model','Balanced_accuracy']].style.background_gradient(cmap='GnBu').set_properties(**{
  'font-family': 'Lucida Calligraphy',
  'color': 'neon',
  'font-size': '15px'
})

print("\nComparison Table:")
comparison_table

classifiers = new_df['Model']
Fit_time = new_df['Fit_time']

# sort accuracy in descending order but doesn't reassign to 'accuracy' variable
sorted_Fit_time = Fit_time.sort_values(ascending=False)

y = range(len(classifiers))

fig, ax = plt.subplots(figsize=(9, 5))

bars = ax.barh(y, sorted_Fit_time, color='#f4d35e')

ax.set_xlabel('Fit time')
ax.set_title('Model Accuracy Comparison')
ax.set_yticks(y)
ax.set_yticklabels(classifiers)
ax.invert_yaxis()  # labels read top-to-bottom

for bar in bars:
    width = bar.get_width()
    label_x_pos = width if width > 0 else width - 0.05
    ax.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.2f}',
            va='center', ha='right' if width > 0 else 'left', color='blue')

fig.tight_layout()

plt.show()

"""### **We can Conclude that Tuned model with Subategory LDA features and Binary Classification with 11 PCA components and LDA using Subcategory are the best**




"""